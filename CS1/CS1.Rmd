---
title: "Econometrics 1 - Case Study 1 - WS 22/23"
author: '01226080, '
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 0 Import data

```{r}
data = read.csv("ELCONS_GDP.csv")
head(data)
```

## 1 Data Analysis

```{r}
summary(data)
```

The mean, median, minimum and maximum of the total energy consumption ($TOTALCONS$) and the GDP can be found in the cell's output above.


```{r}
#define plot labels
xlabel="GDP [M$]"
ylabel="Total energy consumption [GWh]"
xloglabel="GDP [log10(M$)]"
yloglabel="Total energy consumption [log10(GWh)]"


```


```{r}
plot(data$GDP, data$TOTALCONS,
     main="Total energy consumption over GDP in the year 2000",
     xlab=xlabel,
     ylab=ylabel)
```

Not much is visible, as this is the wrong way to plot multiplicative growth processes.
One can see an extreme outlier on the top right.
With this visualization no certain judgement can be made about the relationship of variables.

```{r}
plot(log10(data$GDP), log10(data$TOTALCONS),
     main="loglog plot of Total energy consumption over GDP in the year 2000",
     xlab=xloglabel,
     ylab=yloglabel)
```

This is the log-log-plot, where the logarithm to the basis $10$ is plotted for both variables/axes.

The outlier is still there of course, but lies on the imaginary eyeballed regression line. Because a clear line can be drawn by hand which incorporates most data points, a linear relationship with a high correlation and dependence can be assumed. We will investigate this assumption now by calculating it. 


## 1.2 Simple linear regression

A simple linear regression with a vanishing error term ($E(u)=0$) is easily possible with built-in commands:


```{r cars}
ols = lm(
         TOTALCONS ~ GDP,
         data = data
)
summary(ols)
ols$coefficients
```

The OLS estimates for $\hat{\beta_0}$ is $-3754 \ GWh$ and for $\hat{\beta_1}$ is $0.3380 \ \frac{GWh}{M\$} = 3380 \frac{GWh}{G\$} = 3380 \frac{Wh}{\$}$.
$\hat{\beta_1}$ is the coefficient associated with an increase of GDP. This means that, in the model, an increase of $1 \ M\$$ results in an increase of $0.338 \ GWh$.

```{r}
summary(ols)
```


### 1.3 Plot 

```{r message=FALSE}
#install.packages("dplyr")
library(dplyr)
#install.packages("ggplot2")
library(ggplot2)
```


```{r}

data %>% ggplot(mapping = aes(x = GDP, y = TOTALCONS)) +
  theme_minimal() +
  geom_point() +
  #geom_smooth(method = "lm", se = FALSE) + #no standard error plotted
  geom_smooth(method = "lm") +
  labs(x=xlabel, y=ylabel,
       title="Can an increase in GDP explain the increase in total energy consumption?",
       subtitles="Yes! The linear regression model explains about 97,6% of the data.",
       caption="linear regression model parameters: -37542+0.3379*GDP") +
  scale_x_continuous(trans='log10') +
  scale_y_continuous(trans='log10')


```

We can see a very strong linear relationship between the GDP and total energy consumption, which is supported by the value of $R^2 = 97.6\%$ in the model's output.


## 1.4 Residual plot of Model 1



## 1.5 Log-log-linear Model

We will now use a log-log-linear model, where X and Y are log-transformed:

$$
log(Y) = \beta_0 + \beta_1 log(X) + u, \ \ E[u|log(X)]=0
$$
We can rewrite this simply by using the inverse of the natural logarithm, which is the exponential function.

$$
Y = e^{\beta_0 + \beta_1 log(X) + u} = 
e^{\beta_0} \cdot e^{\beta_1 log(X)} \cdot e^u = 
\tilde{\beta_0} \cdot X^{\beta_1} \cdot \tilde{u}
$$

R can handle the implicit definition as given in the first equation:

```{r}
mdl2 = lm(
         log(TOTALCONS) ~ log(GDP),
         data = data
)
summary(mdl2)
```

```{r}
mdl2$coefficients
```
The values of this model for $\hat{\beta_0}$ is $-0.2539 \ log(GWh)$ and for $\hat{\beta_1}$ it is $0.9187 \ \frac{log(GWh)}{log(M\$)}$.
$\hat{\beta_1}$ is the coefficient associated with an increase of the logarithm of GDP. This means that, in the model, an increase of $1\%$ results in an increase of $0.9187\%$.

## 1.6 Plot of Model 2 (the log-log-linear model)


## 1.7 Numerical implications

### a


### b


### c



## 1.8 Model generalization discussion



## 1.9 Bonusquestion





# 2 Theory



